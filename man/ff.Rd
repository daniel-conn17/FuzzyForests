% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fuzzyforest_fit.R
\name{ff}
\alias{ff}
\title{Fits fuzzy forest algorithm.}
\usage{
ff(X, y, Z = NULL, module_membership,
  screen_params = screen_control(min_ntree = 5000),
  select_params = select_control(min_ntree = 5000), final_ntree = 5000,
  num_processors = 1, nodesize, test_features = NULL, test_y = NULL)
}
\arguments{
\item{X}{A data.frame.
Each column corresponds to a feature vectors.}

\item{y}{Response vector.  For classification, y should be a
factor.  For regression, y should be
numeric.}

\item{Z}{A data.frame. Additional features that are not to be
screened out at the screening step.}

\item{module_membership}{A character vector giving the module membership of
each feature.}

\item{screen_params}{Parameters for screening step of fuzzy forests.
See \code{\link[fuzzyforest]{screen_control}} for
details. \code{screen_params} is an object of type
\code{screen_control}.}

\item{select_params}{Parameters for selection step of fuzzy forests.
See \code{\link[fuzzyforest]{select_control}} for details.
\code{select_params} is an object of type
\code{select_control}.}

\item{final_ntree}{Number of trees grown in the final random forest.
This random forest contains all selected features.}

\item{num_processors}{Number of processors used to fit random forests.}

\item{nodesize}{Minimum terminal nodesize. 1 if classification.
5 if regression.  If the sample size is very large,
the trees will be grown extremely deep.
This may lead to issues with memory usage and may
lead to significant increases in the time it takes
the algorithm to run.  In this case,
it may be useful to increase \code{nodesize}.}

\item{test_features}{A data.frame containing features from a test set.
The data.frame should contain the features in both
X and Z.}

\item{test_y}{The responses for the test set.}
}
\value{
An object of type \code{\link[fuzzyforest]{fuzzy_forest}}.  This
object is a list containing useful output of fuzzy forests.
In particular it contains a data.frame with list of selected features.
It also includes the random forest fit using the selected features.
}
\description{
Fits fuzzy forest algorithm.  Returns
fuzzy forest object.
}
\note{
This work was partially funded by NSF IIS 1251151 and AMFAR 8721SC.
}
\examples{
#ff requires that the partition of the covariates be previously determined.
#ff is handy if the user wants to test out multiple settings of WGCNA
#prior to running fuzzy forests.
library(mvtnorm)
library(fuzzyforest)
#Each row corresponds to one sample.
gen_mod <- function(n, p, corr) {
 sigma <- matrix(corr, nrow=p, ncol=p)
 diag(sigma) <- 1
 X <- rmvnorm(n, sigma=sigma)
 return(X)
}

gen_X <- function(n, mod_sizes, corr){
 m <- length(mod_sizes)
 X_list <- vector("list", length = m)
 for(i in 1:m){
   X_list[[i]] <- gen_mod(n, mod_sizes[i], corr[i]) 
 }
 X <- do.call("cbind", X_list)
 return(X)
}

err_sd <- .5
n <- 500
mod_sizes <- rep(25, 4)
corr <- rep(.8, 4)
X <- gen_X(n, mod_sizes, corr)
beta <- rep(0, 100)
beta[c(1:4, 76:79)] <- 4
y <- X\%*\%beta + rnorm(n, sd=err_sd)
X <- as.data.frame(X)

cdist <- as.dist(1 - cor(X))
fit <- hclust(cdist, method="ward.D")
groups <- cutree(fit, k=4)

screen_c <- screen_control(keep_fraction = .25)
select_c <- select_control(number_selected = 10)
\donttest{
ff_fit <- ff(X, y, module_membership = groups,
            screen_params = screen_c,
            select_params = select_c,
            final_ntree = 5000)
#extract variable importance rankings
vims <- ff_fit$feature_list

#plot results
modplot(ff_fit)
}
}
\references{
Leo Breiman (2001). Random Forests. Machine Learning, 45(1), 5-32.

Daniel Conn, Tuck Ngun, Christina M. Ramirez (2015). Fuzzy Forests: a New
WGCNA Based Random Forest Algorithm for Correlated, High-Dimensional Data,
Journal of Statistical Software, Manuscript in progress.

Bin Zhang and Steve Horvath (2005) "A General Framework for Weighted Gene
Co-Expression Network Analysis", Statistical Applications in Genetics and
Molecular Biology: Vol. 4: No. 1, Article 17
}
